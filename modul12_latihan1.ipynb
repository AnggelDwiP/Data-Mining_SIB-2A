{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDuR+40jxkRkyXU7h8TQjD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnggelDwiP/Data-Mining_SIB-2A/blob/main/modul12_latihan1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c52Kn4gAdBoQ",
        "outputId": "8396eb82-fdc1-4672-b996-e73a96b10a9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(891, 12)\n",
            "             count        mean         std   min       25%       50%    75%  \\\n",
            "PassengerId  891.0  446.000000  257.353842  1.00  223.5000  446.0000  668.5   \n",
            "Survived     891.0    0.383838    0.486592  0.00    0.0000    0.0000    1.0   \n",
            "Pclass       891.0    2.308642    0.836071  1.00    2.0000    3.0000    3.0   \n",
            "Age          714.0   29.699118   14.526497  0.42   20.1250   28.0000   38.0   \n",
            "SibSp        891.0    0.523008    1.102743  0.00    0.0000    0.0000    1.0   \n",
            "Parch        891.0    0.381594    0.806057  0.00    0.0000    0.0000    0.0   \n",
            "Fare         891.0   32.204208   49.693429  0.00    7.9104   14.4542   31.0   \n",
            "\n",
            "                  max  \n",
            "PassengerId  891.0000  \n",
            "Survived       1.0000  \n",
            "Pclass         3.0000  \n",
            "Age           80.0000  \n",
            "SibSp          8.0000  \n",
            "Parch          6.0000  \n",
            "Fare         512.3292  \n",
            "Akurasi: 81.01%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "Not Survived       0.80      0.90      0.85       105\n",
            "    Survived       0.83      0.68      0.75        74\n",
            "\n",
            "    accuracy                           0.81       179\n",
            "   macro avg       0.82      0.79      0.80       179\n",
            "weighted avg       0.81      0.81      0.81       179\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('Titanic-Dataset.csv')\n",
        "print(df.shape)\n",
        "print(df.describe().transpose())\n",
        "\n",
        "# Select features and target variable\n",
        "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
        "X = df[features]\n",
        "y = df['Survived']\n",
        "\n",
        "# Preprocessing for numerical data\n",
        "numerical_features = ['Age', 'SibSp', 'Parch', 'Fare']\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Preprocessing for categorical data\n",
        "categorical_features = ['Pclass', 'Sex', 'Embarked']\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Combine preprocessing steps\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Create preprocessing and training pipeline\n",
        "clf = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', MLPClassifier(hidden_layer_sizes=(10,), max_iter=1000, alpha=0.01, solver='adam', random_state=42))\n",
        "])\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Akurasi: {accuracy * 100:.2f}%')\n",
        "print(classification_report(y_test, y_pred, target_names=['Not Survived', 'Survived']))\n"
      ]
    }
  ]
}